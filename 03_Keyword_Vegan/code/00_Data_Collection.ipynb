{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/vegan-logo-resized.png\" style=\"float: right; margin: 10px;\">\n",
    "\n",
    "# Data Collection\n",
    "\n",
    "Author: Gifford Tompkins\n",
    "\n",
    "---\n",
    "\n",
    "Project 03 | Notebook 0 of 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The objective of this notebook is to scrape a substantial body of posts from the two subreddits [r/Vegan](https://www.reddit.com/r/vegan/) and [r/Vegetarian](https://www.reddit.com/r/vegetarian/) and to save them into a CSV file for preprocessing and data cleaning, to be completed in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Collection\" data-toc-modified-id=\"Data-Collection-1\">Data Collection</a></span></li><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-2\">Objective</a></span></li><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-3\">Import Libraries</a></span></li><li><span><a href=\"#Collecting-Data-Using-pushshift.io\" data-toc-modified-id=\"Collecting-Data-Using-pushshift.io-4\">Collecting Data Using <em>pushshift.io</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-corpus\" data-toc-modified-id=\"Creating-the-corpus-4.1\">Creating the corpus</a></span></li><li><span><a href=\"#Confirm-the-corpus\" data-toc-modified-id=\"Confirm-the-corpus-4.2\">Confirm the corpus</a></span></li></ul></li><li><span><a href=\"#Summary-and-Conclusion\" data-toc-modified-id=\"Summary-and-Conclusion-5\">Summary and Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions saved in repository\n",
    "from project_functions.data_collection import get_data_json, create_doc, append_to_corpus    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data Using _pushshift.io_\n",
    "\n",
    "We will be collecting posts (or documents, as they will be referred to in this notebook) through the [pushshift.io API](https://pushshift.io/). For that we will submit a base `url` with a dictionary of parameters. One of those parameters being the name of the subbreddit, either `r/Vegan` or `r/Vegetarian`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/submission/search'\n",
    "subreddits = ['Vegetarian','Vegan']  \n",
    "corpus_csv = '../data/api_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the corpus\n",
    "We will create an empty dataframe to be saved as our `api_data.csv` that we can append each new batch of documents onto. Since we will be doing multiple pulls and hopefully getting up to 20,000 rows of data, we would like to save our data as we go in the event that our connection breaks or our function or program times out.\n",
    "\n",
    "For custom functions used in this section, see the [data collection code](./project_functions/data_collection.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store our corpus as a csv file\n",
    "df = pd.DataFrame(columns=['title','selftext','vegan'])\n",
    "df.to_csv(corpus_csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r/Vegetarian\nPull number 1\n500 documents appended to corpus.\nr/Vegetarian\nPull number 2\n500 documents appended to corpus.\nr/Vegetarian\nPull number 3\n500 documents appended to corpus.\nr/Vegetarian\nPull number 4\n500 documents appended to corpus.\nr/Vegetarian\nPull number 5\n500 documents appended to corpus.\nr/Vegetarian\nPull number 6\n500 documents appended to corpus.\nr/Vegetarian\nPull number 7\n500 documents appended to corpus.\nr/Vegetarian\nPull number 8\n500 documents appended to corpus.\nr/Vegetarian\nPull number 9\n500 documents appended to corpus.\nr/Vegetarian\nPull number 10\n500 documents appended to corpus.\nr/Vegetarian\nPull number 11\n500 documents appended to corpus.\nr/Vegetarian\nPull number 12\n500 documents appended to corpus.\nr/Vegetarian\nPull number 13\n500 documents appended to corpus.\nr/Vegetarian\nPull number 14\n500 documents appended to corpus.\nr/Vegetarian\nPull number 15\n500 documents appended to corpus.\nr/Vegetarian\nPull number 16\n500 documents appended to corpus.\nr/Vegetarian\nPull number 17\n500 documents appended to corpus.\nr/Vegetarian\nPull number 18\n500 documents appended to corpus.\nr/Vegetarian\nPull number 19\n500 documents appended to corpus.\nr/Vegetarian\nPull number 20\n500 documents appended to corpus.\nr/Vegan\nPull number 1\n500 documents appended to corpus.\nr/Vegan\nPull number 2\n500 documents appended to corpus.\nr/Vegan\nPull number 3\n500 documents appended to corpus.\nr/Vegan\nPull number 4\n500 documents appended to corpus.\nr/Vegan\nPull number 5\n500 documents appended to corpus.\nr/Vegan\nPull number 6\n500 documents appended to corpus.\nr/Vegan\nPull number 7\n500 documents appended to corpus.\nr/Vegan\nPull number 8\n500 documents appended to corpus.\nr/Vegan\nPull number 9\n500 documents appended to corpus.\nr/Vegan\nPull number 10\n500 documents appended to corpus.\nr/Vegan\nPull number 11\n500 documents appended to corpus.\nr/Vegan\nPull number 12\n500 documents appended to corpus.\nr/Vegan\nPull number 13\n500 documents appended to corpus.\nr/Vegan\nPull number 14\n500 documents appended to corpus.\nr/Vegan\nPull number 15\n500 documents appended to corpus.\nr/Vegan\nPull number 16\n500 documents appended to corpus.\nr/Vegan\nPull number 17\n500 documents appended to corpus.\nr/Vegan\nPull number 18\n500 documents appended to corpus.\nr/Vegan\nPull number 19\n500 documents appended to corpus.\nr/Vegan\nPull number 20\n500 documents appended to corpus.\n"
    }
   ],
   "source": [
    "# Loop through the two subreddits and pull the document batches with the pushift.io api.\n",
    "for i, sub in enumerate(subreddits):\n",
    "    \n",
    "    # Instantiate and define the url parameters dictionary.\n",
    "    url_params = {\n",
    "        'subreddit': sub,\n",
    "        'size': 500\n",
    "    }\n",
    "    \n",
    "    # Pull 20 batches of posts for each subreddit.\n",
    "    for count in range(20):\n",
    "        \n",
    "        # Pull data from json\n",
    "        posts = get_data_json(count, url, url_params)\n",
    "\n",
    "        # Instantiate the bath of documents as a list item\n",
    "        documents = []\n",
    "        \n",
    "        for post in posts:\n",
    "            \n",
    "            # Create a document from the post using the custom function create_doc\n",
    "            # Classify the post as Vegan post: 1 or a Vegetarian post: 0\n",
    "            document = create_doc(i, post)\n",
    "            \n",
    "            # Append the document onto the documents batch\n",
    "            documents.append(document)\n",
    "        \n",
    "        # Append the batch of documents to the corpus using the custom function append_to_corpus\n",
    "        append_to_corpus(documents, corpus_csv)\n",
    "        \n",
    "        # Update 'before' paramter in url_params before running next batch.\n",
    "        url_params['before'] = post['created_utc']\n",
    "\n",
    "        # Put a delay on our loop to slow down api usage\n",
    "        time.sleep(10)\n",
    "        \n",
    "    # Remove the before parameter so that it can be redefined in the next subreddit\n",
    "    url_params.pop('before')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm the corpus\n",
    "Confirm that the posts have been pulled and that the data looks appropriate. We will do more extensive data-cleaning and EDA in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/api_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               title selftext  vegan\n0  Due to lack of options at the store right now,...      NaN      0\n1  Fettuccine Alfredo with mushrooms and broccoli...      NaN      0\n2  Savoury semolina crepe with veggies and schezw...      NaN      0\n3                              Good ol avocado toast      NaN      0\n4                                             Hummus      NaN      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>selftext</th>\n      <th>vegan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Due to lack of options at the store right now,...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fettuccine Alfredo with mushrooms and broccoli...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Savoury semolina crepe with veggies and schezw...</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good ol avocado toast</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hummus</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   title  \\\n19995  Eat the shitty food pyramid or hey the conspir...   \n19996  New California Bill Seeks To Ban Seaworld's Wh...   \n19997  How should I answer “why are you vegan” in the...   \n19998  Lentil pasta with spinach and pinto bean “bole...   \n19999                        Vegan diet and brain health   \n\n                                                selftext  vegan  \n19995                                                NaN      1  \n19996                                                NaN      1  \n19997  Part of me feels that I shouldn’t be expected ...      1  \n19998                                                NaN      1  \n19999  Hey guys I have been recently touting all the ...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>selftext</th>\n      <th>vegan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19995</th>\n      <td>Eat the shitty food pyramid or hey the conspir...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>New California Bill Seeks To Ban Seaworld's Wh...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>How should I answer “why are you vegan” in the...</td>\n      <td>Part of me feels that I shouldn’t be expected ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>Lentil pasta with spinach and pinto bean “bole...</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>Vegan diet and brain health</td>\n      <td>Hey guys I have been recently touting all the ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    10000\n0    10000\nName: vegan, dtype: int64"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data['vegan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "title       0.0000\nselftext    0.5908\nvegan       0.0000\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> Appears to be some duplicates and the selftext column has selveral null values, but all items are stored properly in the [`corpus.csv`](./data/api_data.csv). The first posts are vegetarian while last posts are vegan and we have pulled equal numbers of posts from each subreddit.  \n",
    ">\n",
    "> The corpus looks ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Conclusion\n",
    "We have gathered a solid body of data for our NLP analysis. We did this through submitting batch request through the pushift.io API. We then stored the data of interest into a corpus that we saved as a CSV.\n",
    "\n",
    "In the next notebook we will clean our data and do some initial exploratory analysis. After that we will have a better sense of direction for building our Vegan classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv-dsi-project-03': venv)",
   "language": "python",
   "name": "python38164bitvenvdsiproject03venv79b6c0fd74c34c6e94925be127e444e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}