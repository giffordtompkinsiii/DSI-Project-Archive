{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"../images/vegan-logo-resized.png\" style=\"float: right; margin: 10px;\">\n",
    "\n",
    "# Data Cleaning and Exploratory Data Analysis\n",
    "\n",
    "Author: Gifford Tompkins\n",
    "\n",
    "---\n",
    "\n",
    "Project 03 | Notebook 1 of 6\n",
    "\n",
    "## OBJECTIVE\n",
    "This notebook will establish a Base Model to compare our final model's success to. We will then clean the data and make it ready fro analysis. We will then begin some Exploratory Data Analysis and attempt to get a sense of whether or not we will be able to answer our problem statement given our body of data. If so, we will also have a sense for how to develop a strategy for building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import regex as re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from project_functions.data_cleaning_and_eda import clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/corpus.csv')\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates\n",
    "Before establishing a baseline model, we will remove any duplicates from our data set to establish a valid class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.501411\n",
       "1    0.498589\n",
       "Name: vegan, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vegan'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "Our baseline model is the majority class distribution of our data set. We will attempt to create a model with more accuracy than a naive guess. \n",
    "\n",
    "We have a class distribution of \n",
    "\n",
    "|Vegan|Vegetarian|\n",
    "|---|---|\n",
    "|49.9%|50.1%|\n",
    "\n",
    "So our baseline score is that of the majority class **Vegetarians**, at **50.42%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score = 1 - df['vegan'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "We will look through our data and see if anything needs to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>vegan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My ‚Äò100 calories club‚Äô which helps people visu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chilli fritters stuffed with a mix of raw onio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lentil and mushroom gravy with sweetpotato mas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to get excited about vegetables?</td>\n",
       "      <td>I stopped eating meat after 24 years due to a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Rasgulla - Bengali Spongy Milk Sweets...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Homemade Rasgulla - Bengali Spongy Milk Sweets...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Supporting a vegetarian diet!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leek and mint puree with oyster mushroom 'scal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What's for Dinner? Discussion</td>\n",
       "      <td>Welcome to our weekly discussion on what you‚Äôr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lumpin beans! 36% of protein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  My ‚Äò100 calories club‚Äô which helps people visu...   \n",
       "1  Chilli fritters stuffed with a mix of raw onio...   \n",
       "2  Lentil and mushroom gravy with sweetpotato mas...   \n",
       "3               How to get excited about vegetables?   \n",
       "4  Homemade Rasgulla - Bengali Spongy Milk Sweets...   \n",
       "5  Homemade Rasgulla - Bengali Spongy Milk Sweets...   \n",
       "6                      Supporting a vegetarian diet!   \n",
       "7  Leek and mint puree with oyster mushroom 'scal...   \n",
       "8                      What's for Dinner? Discussion   \n",
       "9                       Lumpin beans! 36% of protein   \n",
       "\n",
       "                                            selftext  vegan  \n",
       "0                                                NaN      0  \n",
       "1                                                NaN      0  \n",
       "2                                                NaN      0  \n",
       "3  I stopped eating meat after 24 years due to a ...      0  \n",
       "4                                                NaN      0  \n",
       "5                                                NaN      0  \n",
       "6                                                NaN      0  \n",
       "7                                                NaN      0  \n",
       "8  Welcome to our weekly discussion on what you‚Äôr...      0  \n",
       "9                                                NaN      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0.000000\n",
       "selftext    0.582756\n",
       "vegan       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "The `'selftext'` column has many `null` values as well as several instances of the phrase `'[removed]'`. This is how the API records the fact that a post contained body text but that text was then removed (either by the user or the subreddit or reddit moderators).  \n",
    "\n",
    "We will address both of these issues by replacing them with the empty string. The textual version of a `null` value.\n",
    "\n",
    "Fortunately, `'titles'` and `'vegan'`  have no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegan\n",
       "0    140\n",
       "1    133\n",
       "Name: selftext, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_removed = df['selftext']=='[removed]'\n",
    "df[mask_removed].groupby(by='vegan')['selftext'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `'removed'` column\n",
    "Vegans twice as many `'[removed]'` posts as Vegetarians. This fact might end up being signaling, so I am going to save that information in a new column called 'removed_post'. I will then remove the `'[removed]'` string from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['removed'] = (mask_removed).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegan\n",
       "0    140\n",
       "1    133\n",
       "Name: removed, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the new column was created correctly.\n",
    "df.groupby(by='vegan')['removed'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>vegan</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are some brands of prepackaged stuff that...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Anyone has suggestion on good veggie sausages?...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>I‚Äôm Veg, my BF adores meat. What can we cook f...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ridge Gourd Gravy | Gravy For Dosa, Idli, Poor...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>I'm going backpacking with some non vegetarian...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title   selftext  vegan  \\\n",
       "18  What are some brands of prepackaged stuff that...  [removed]      0   \n",
       "23  Anyone has suggestion on good veggie sausages?...  [removed]      0   \n",
       "50  I‚Äôm Veg, my BF adores meat. What can we cook f...  [removed]      0   \n",
       "75  Ridge Gourd Gravy | Gravy For Dosa, Idli, Poor...  [removed]      0   \n",
       "92  I'm going backpacking with some non vegetarian...  [removed]      0   \n",
       "\n",
       "    removed  \n",
       "18        1  \n",
       "23        1  \n",
       "50        1  \n",
       "75        1  \n",
       "92        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask_removed].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all '[removed]' values with null values\n",
    "df['selftext'] = df['selftext'].where(~mask_removed,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>vegan</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are some brands of prepackaged stuff that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Anyone has suggestion on good veggie sausages?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>I‚Äôm Veg, my BF adores meat. What can we cook f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ridge Gourd Gravy | Gravy For Dosa, Idli, Poor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>I'm going backpacking with some non vegetarian...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô ‡∏¢‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏†‡∏≤‡∏ß‡∏∞‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏≠‡∏µ‡∏Å ‡πÅ‡∏°‡πâ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏∏‡πà...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>What I think when people say \"plants feel pain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>‡∏ô‡∏±‡∏Å‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÇ‡∏ä‡∏Ñ‡∏•‡∏∏‡πâ‡∏ô‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡∏±‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏ô‡∏ï‡πå‡πÉ‡∏ô‡∏®‡∏≤‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏¢‡∏ï‡∏≤! \"‡∏ã‡∏±‡∏á‡∏≠‡∏≤\" ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡πà‡πÇ‡∏¢‡∏Ñ‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏¥‡πà‡∏á‡∏™‡∏∏‡∏î‡πÄ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>dont know how it work but f it :D i am a chef ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title selftext  vegan  \\\n",
       "18    What are some brands of prepackaged stuff that...      NaN      0   \n",
       "23    Anyone has suggestion on good veggie sausages?...      NaN      0   \n",
       "50    I‚Äôm Veg, my BF adores meat. What can we cook f...      NaN      0   \n",
       "75    Ridge Gourd Gravy | Gravy For Dosa, Idli, Poor...      NaN      0   \n",
       "92    I'm going backpacking with some non vegetarian...      NaN      0   \n",
       "...                                                 ...      ...    ...   \n",
       "4032  ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô ‡∏¢‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏†‡∏≤‡∏ß‡∏∞‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏≠‡∏µ‡∏Å ‡πÅ‡∏°‡πâ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏∏‡πà...      NaN      1   \n",
       "4041  What I think when people say \"plants feel pain...      NaN      1   \n",
       "4050  ‡∏ô‡∏±‡∏Å‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÇ‡∏ä‡∏Ñ‡∏•‡∏∏‡πâ‡∏ô‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡∏±‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏ô‡∏ï‡πå‡πÉ‡∏ô‡∏®‡∏≤‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÅ...      NaN      1   \n",
       "4051  ‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏¢‡∏ï‡∏≤! \"‡∏ã‡∏±‡∏á‡∏≠‡∏≤\" ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡πà‡πÇ‡∏¢‡∏Ñ‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏¥‡πà‡∏á‡∏™‡∏∏‡∏î‡πÄ...      NaN      1   \n",
       "4057  dont know how it work but f it :D i am a chef ...      NaN      1   \n",
       "\n",
       "      removed  \n",
       "18          1  \n",
       "23          1  \n",
       "50          1  \n",
       "75          1  \n",
       "92          1  \n",
       "...       ...  \n",
       "4032        1  \n",
       "4041        1  \n",
       "4050        1  \n",
       "4051        1  \n",
       "4057        1  \n",
       "\n",
       "[273 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that values have been replaced.\n",
    "df[mask_removed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Empty Strings\n",
    "Now, for the null values in the `selftext` column, we are going to impute empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = df['selftext'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>vegan</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My ‚Äò100 calories club‚Äô which helps people visu...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chilli fritters stuffed with a mix of raw onio...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lentil and mushroom gravy with sweetpotato mas...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to get excited about vegetables?</td>\n",
       "      <td>I stopped eating meat after 24 years due to a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Rasgulla - Bengali Spongy Milk Sweets...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  My ‚Äò100 calories club‚Äô which helps people visu...   \n",
       "1  Chilli fritters stuffed with a mix of raw onio...   \n",
       "2  Lentil and mushroom gravy with sweetpotato mas...   \n",
       "3               How to get excited about vegetables?   \n",
       "4  Homemade Rasgulla - Bengali Spongy Milk Sweets...   \n",
       "\n",
       "                                            selftext  vegan  removed  \n",
       "0                                                         0        0  \n",
       "1                                                         0        0  \n",
       "2                                                         0        0  \n",
       "3  I stopped eating meat after 24 years due to a ...      0        0  \n",
       "4                                                         0        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `'text'` Column\n",
    "To simplify the vectorization, we will create a column with all of our textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>vegan</th>\n",
       "      <th>removed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My ‚Äò100 calories club‚Äô which helps people visu...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My ‚Äò100 calories club‚Äô which helps people visu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chilli fritters stuffed with a mix of raw onio...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chilli fritters stuffed with a mix of raw onio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lentil and mushroom gravy with sweetpotato mas...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lentil and mushroom gravy with sweetpotato mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to get excited about vegetables?</td>\n",
       "      <td>I stopped eating meat after 24 years due to a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to get excited about vegetables? I stopped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Rasgulla - Bengali Spongy Milk Sweets...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Homemade Rasgulla - Bengali Spongy Milk Sweets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  My ‚Äò100 calories club‚Äô which helps people visu...   \n",
       "1  Chilli fritters stuffed with a mix of raw onio...   \n",
       "2  Lentil and mushroom gravy with sweetpotato mas...   \n",
       "3               How to get excited about vegetables?   \n",
       "4  Homemade Rasgulla - Bengali Spongy Milk Sweets...   \n",
       "\n",
       "                                            selftext  vegan  removed  \\\n",
       "0                                                         0        0   \n",
       "1                                                         0        0   \n",
       "2                                                         0        0   \n",
       "3  I stopped eating meat after 24 years due to a ...      0        0   \n",
       "4                                                         0        0   \n",
       "\n",
       "                                                text  \n",
       "0  My ‚Äò100 calories club‚Äô which helps people visu...  \n",
       "1  Chilli fritters stuffed with a mix of raw onio...  \n",
       "2  Lentil and mushroom gravy with sweetpotato mas...  \n",
       "3  How to get excited about vegetables? I stopped...  \n",
       "4  Homemade Rasgulla - Bengali Spongy Milk Sweets...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['title'] + ' ' + df['selftext']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize and Standardize Text Column\n",
    "For our next piece of cleaning, we will use the custom function called `clean_string` that will strip any HTML-formatting elements from our string and then pass that string through a WordNetLemmatizer. \n",
    "\n",
    "The lemmatizer will reduce our vocabulary by converting words to their basic forms. \n",
    "- For example: \"ran\" and \"run\" will both be converted to \"run\" and counted as the same vocabulary word.\n",
    "\n",
    "We may lose some signal by doing this, but it will help out analysis in the long-run. When we convert this data into its final form for analysis, every word or phrase will be considered a feature. Thus, if we can cut down the number of features, we will cut down the amount of time and processing power necessary to fit and evaluate our models.\n",
    "\n",
    "To see the code and documentation for this function, see the [`data_cleaning`](./project_functions/data_cleaning_and_eda.py) code stored in the [`project_functions`](./project_functions/) folder in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Duplicates and the Reason for Beautiful Soup\n",
    "Notice the first two titles of our dataset. They were not removed with our initial duplicate drop and are considered unique because of a few non textual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handmade Pasta in a Wild Chanterelle Alfredo Sauce\n",
      "Handmade Pasta in a Wild Chanterelle üçÑAlfredo Sauce\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[241,'title'])\n",
    "print(df.loc[242,'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python does not consider these two strings as identical.\n",
    "df['text'][241] == df['text'][242]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">When we clean the strings, they will be converted into a form that is identified as identical. This will ultimately help us reduce the amount of _noise_ in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-aa1480f4c3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check that the cleaned versions of our strings would be read as identical.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m241\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m242\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/venv-project-03/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3968\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m         \"\"\"\n\u001b[0;32m-> 3970\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   3972\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/venv-project-03/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dsi/projects/DSI-Project-Archive/03_Keyword_Vegan/code/project_functions/data_cleaning_and_eda.py\u001b[0m in \u001b[0;36mclean_string\u001b[0;34m(dirty_string, lemmatizer)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirty_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m'''Pass `dirty_string` through `soupify` and `convert_contraction` to finally lemmatize the data for parsing.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0msouped_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoupify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirty_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mexpanded_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconvert_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msouped_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mregex_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\W'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpanded_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dsi/projects/DSI-Project-Archive/03_Keyword_Vegan/code/project_functions/data_cleaning_and_eda.py\u001b[0m in \u001b[0;36msoupify\u001b[0;34m(html_string)\u001b[0m\n\u001b[1;32m    142\u001b[0m     '''\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0msouped_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'‚Äô'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msouped_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/venv-project-03/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mbuilder_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 raise FeatureNotFound(\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "# Check that the cleaned versions of our strings would be read as identical.\n",
    "df['text'].map(clean_string)[241] == df['text'].map(clean_string)[242]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When we pass the strings through `clean_string` they are interpreted as identical. We can use this to further refine our data, drop more duplicated columns and reduce more noise.  \n",
    ">\n",
    "> We will pass the `keep='last'` parameter into the drop duplicates method so as to keep the (closest to) original post, we will also only drop duplicates from the same subreddits. Finally, we will drop any posts that, after the cleaning, are only the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset=['text','vegan'],keep='last')\n",
    "df = df[df['text'].str.strip()!='']\n",
    "print(df.shape)\n",
    "# Dropped: 174 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm one of our first duplicates have been resolved.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Cleaned Data Frame\n",
    "We will save our cleaned data frame and use this in our subsequent exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = '../datasets/data.csv'\n",
    "df.to_csv(data_csv,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "In this notebook, we cleaned our data to prepare it for some exploratory analysis. We removed duplicates and empty strings and standardized our data from HTML formatting to plain text using BeautifulSoup and some custom functions. We then combined all of our textual data into a single corpus and saved this all to our [`data.csv`]('../datasets/data.csv').\n",
    "\n",
    "In our next notebook, we will perform some exploratory analysis before building our first models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
